# Diabetic Retinopathy Binary Classification

A deep learning pipeline for binary classification of Diabetic Retinopathy images using PyTorch. This project classifies retinal images into two categories:
- **Negative**: No DR and Mild DR (referrable cases)
- **Positive**: Moderate, Severe, and Proliferative DR (non-referrable cases)

## ğŸ“ Project Structure

```
remidio/
â”œâ”€â”€ archive/                          # Data directory
â”‚   â”œâ”€â”€ gaussian_filtered_images/     # Preprocessed retinal images
â”‚   â”œâ”€â”€ train_binary.csv              # Training split
â”‚   â”œâ”€â”€ val_binary.csv                # Validation split
â”‚   â”œâ”€â”€ test_binary.csv               # Test split
â”‚   â””â”€â”€ dataset_stats.json            # Dataset statistics
â”œâ”€â”€ src/                              # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Configuration parameters
â”‚   â”œâ”€â”€ dataset.py                    # Dataset class and data loaders
â”‚   â”œâ”€â”€ model.py                      # Model architectures
â”‚   â”œâ”€â”€ train.py                      # Training logic
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ checkpoints/                      # Saved model checkpoints
â”œâ”€â”€ logs/                             # Training logs and plots
â”œâ”€â”€ main.py                           # Main training script
â”œâ”€â”€ evaluate.py                       # Evaluation script
â”œâ”€â”€ inference.py                      # Inference script
â”œâ”€â”€ EDA.ipynb                         # Exploratory Data Analysis
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd remidio
```

2. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install timm albumentations opencv-python pandas numpy scikit-learn matplotlib seaborn tqdm
```

### Dataset Preparation

Your dataset should be organized as follows:
```
archive/gaussian_filtered_images/
â”œâ”€â”€ No_DR/
â”œâ”€â”€ Mild/
â”œâ”€â”€ Moderate/
â”œâ”€â”€ Severe/
â””â”€â”€ Proliferate_DR/
```

Run the EDA notebook to create the binary splits:
```bash
jupyter notebook EDA.ipynb
```

### Training

Train the model using default configuration:
```bash
python main.py
```

### Evaluation

Evaluate the trained model on the test set:
```bash
python evaluate.py
```

### Inference

Run inference on new images:
```bash
python inference.py
```

Or use the predictor programmatically:
```python
from inference import DRPredictor
from src.config import Config

config = Config()
predictor = DRPredictor('checkpoints/best_model.pth', config)

# Single image prediction
result = predictor.predict('path/to/image.png')
print(result['predicted_label'], result['confidence'])

# Visualize prediction
predictor.visualize_prediction('path/to/image.png')
```

## âš™ï¸ Configuration

Modify `src/config.py` to customize training parameters:

```python
# Model settings
MODEL_NAME = "efficientnet_b3"  # Options: efficientnet_b3, vit_base_patch16_224, densenet121
BATCH_SIZE = 32
NUM_EPOCHS = 50
LEARNING_RATE = 1e-4

# Loss function
LOSS_FUNCTION = "focal"  # Options: focal, ce, weighted_ce
FOCAL_ALPHA = 0.25
FOCAL_GAMMA = 2.0

# Optimizer
OPTIMIZER = "adamw"  # Options: adam, adamw, sgd
SCHEDULER = "cosine"  # Options: cosine, step, plateau
```

## ğŸ—ï¸ Model Architectures

The project supports three state-of-the-art architectures:

### 1. EfficientNet-B3 (Recommended)
- Best balance of accuracy and efficiency
- ~12M parameters
- Fast inference (~15ms per image on GPU)

### 2. Vision Transformer (ViT)
- State-of-the-art performance
- ~86M parameters
- Better for larger datasets

### 3. DenseNet-121
- Lightweight and efficient
- ~8M parameters
- Good for resource-constrained environments

## ğŸ“Š Data Augmentation

Strong augmentation pipeline for medical images:
- Geometric: Flips, rotations, shifts, scaling
- Color: Brightness/contrast adjustment, HSV
- Noise: Gaussian noise, motion blur, Gaussian blur
- Regularization: CoarseDropout (Cutout)

## ğŸ“ˆ Training Features

- âœ… **Focal Loss** for class imbalance handling
- âœ… **Mixed Precision Training** (AMP) for faster training
- âœ… **Cosine Annealing with Warm Restarts** scheduler
- âœ… **Early Stopping** to prevent overfitting
- âœ… **Automatic checkpoint saving** (best F1 score)
- âœ… **Comprehensive metrics** (Accuracy, Precision, Recall, F1, AUC)

## ğŸ“Š Results

Expected performance metrics:
- **Accuracy**: 85-90%
- **F1 Score**: 0.85-0.92
- **AUC-ROC**: 0.90-0.95
- **Sensitivity**: 85-92% (catching positive cases)
- **Specificity**: 85-90% (correctly identifying negatives)

## ğŸ“ Dataset Split

- **Training**: 75% (~2,750 images)
- **Validation**: 10% (~370 images)
- **Test**: 15% (~550 images)

All splits use stratified sampling to maintain class balance.

## ğŸ”§ Advanced Usage

### Custom Training Loop

```python
from src.config import Config
from src.dataset import create_dataloaders
from src.model import create_model, get_loss_function
from src.train import Trainer
import torch.optim as optim

config = Config()

# Create dataloaders
train_loader, val_loader, test_loader = create_dataloaders(
    config.TRAIN_CSV, config.VAL_CSV, config.TEST_CSV,
    config.IMAGE_DIR, config.BATCH_SIZE
)

# Create model
model = create_model(config.MODEL_NAME, pretrained=True)

# Setup training
criterion = get_loss_function('focal', alpha=0.25, gamma=2.0)
optimizer = optim.AdamW(model.parameters(), lr=1e-4)

# Train
trainer = Trainer(model, criterion, optimizer, device='cuda')
history = trainer.fit(train_loader, val_loader, num_epochs=50)
```

### Handling Class Imbalance

If the default focal loss doesn't work well, try:

**Option A: Weighted Sampling**
```python
from torch.utils.data import WeightedRandomSampler

# Calculate class weights
class_counts = [2200, 1460]  # [Negative, Positive]
class_weights = [1/c for c in class_counts]
sample_weights = [class_weights[label] for label in labels]

sampler = WeightedRandomSampler(sample_weights, len(sample_weights))
train_loader = DataLoader(dataset, batch_size=32, sampler=sampler)
```

**Option B: Weighted Loss**
```python
# In config.py
LOSS_FUNCTION = "weighted_ce"
POS_WEIGHT = 1.5  # Increase to give more weight to positive class
```

## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@misc{dr_binary_classification,
  title={Diabetic Retinopathy Binary Classification},
  author={Your Name},
  year={2025},
  publisher={GitHub},
  url={https://github.com/yourusername/remidio}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or issues, please open an issue on GitHub or contact [your-email@example.com].

## ğŸ™ Acknowledgments

- EfficientNet implementation from [timm](https://github.com/rwightman/pytorch-image-models)
- Data augmentation using [Albumentations](https://albumentations.ai/)
- Inspired by various Kaggle kernels on Diabetic Retinopathy detection
